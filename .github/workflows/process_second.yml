name: Run Crawler Script

on:
  schedule:
    - cron: "0 15 * * *" # 매일 자정 UTC 시간으로 설정, 한국시간 자정은 UTC 15시
  workflow_dispatch: # 수동으로 실행할 수 있는 옵션

jobs:
  run-crawler:
    runs-on: ubuntu-latest
    timeout-minutes: 600

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.11" # 원하는 Python 버전으로 변경

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver_manager beautifulsoup4 mysql-connector-python psutil konlpy

      - name: Install ubuntu package # 우분투 관련 패키지도 설치한 후
        run: |
          sudo apt-get install fonts-unfonts-core
          sudo apt-get install fonts-unfonts-extra
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add        
          sudo apt-get update
          sudo apt-get install google-chrome-stable
          wget https://chromedriver.storage.googleapis.com/2.40/chromedriver_linux64.zip
          unzip ./chromedriver_linux64.zip

      - name: Set up Chrome
        uses: browser-actions/setup-chrome@v1

      - name: Set up ChromeDriver
        uses: nanasess/setup-chromedriver@v1

      - name: Run crawler script
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          python process_second_half.py
